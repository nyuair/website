import{j as e}from"./index-0lYHZPgo.js";import{S as n,A as t,N as o,d as r}from"./autoplay-wZ6IDeK0.js";const c="/website/assets/area1-DfyngRRQ.jpg",l="/website/assets/area2-C1TnkdKr.jpg",d="/website/assets/area3-D-Ikl_Pi.jpg",g="/website/assets/area4-H0vEjTd_.jpg",h="/website/assets/area5-BlwJBhvr.jpg",m="/website/assets/area6-BD17u4Tp.jpg",p=[{name:"Exploring the Reliability of Foundation Model-Based Frontier Selection in Zero-Shot Object Goal Navigation",desc:"This project presents a novel method for reliable frontier selection in Zero-Shot Object Goal Navigation (ZS-OGN), enhancing robotic navigation systems with foundation models to improve commonsense reasoning in indoor environments. ",img:"1.jpg",link:"https://haoyu6427.github.io/project_pages/icpr25_exploring/",subtitle:"ICPR 2025"},{name:"GAMap: Zero-Shot Object Goal Navigation with Multi-Scale Geometric-Affordance Guidance",subtitle:"NeurIPS 2024",img:"2.jpg",link:"https://shalexyuan.github.io/GAMap/",desc:"Zero-Shot Object Goal Navigation (ZS-OGN) enables robots to navigate toward objects of unseen categories without prior training."},{name:"Weakly Scene Segmentation Using Efficient Transformer",subtitle:"IROS 2024",img:"3.jpg",link:"https://haoyu6427.github.io/project_pages/iros24_weakly/",desc:"Current methods for large-scale point cloud scene semantic segmentation rely on manually annotated dense point wise labels, which are costly, labor-intensive, and prone to errors. "},{name:"Noisy Few-shot 3D Point Cloud Scene Segmentation",subtitle:"ICRA 2024",img:"4.jpg",link:"https://haoyu6427.github.io/project_pages/icra24_noisy/",desc:"3D scene semantic segmentation plays a crucial role in robotics by enabling robots to understand and interpret their environment in a detailed and context-aware manner, facilitating tasks such as navigation, object manipulation, and interaction within complex spaces."}],j=a=>e.jsx("div",{className:"hero",children:e.jsxs("div",{className:"heromainContents",children:[e.jsx("div",{className:"container fromTopHer",children:e.jsxs("div",{className:"hero-text alignCenter",children:[e.jsx("p",{className:"herotltle",children:a.title}),e.jsx("p",{children:a.description})]})}),e.jsx("div",{className:"faintOverlayEnder",children:e.jsx("div",{className:"container",children:e.jsxs("div",{className:"row",children:[e.jsx("p",{className:"ongoingRhr",children:" Research Projects"}),e.jsx(n,{slidesPerView:3,spaceBetween:0,loop:!0,centeredSlides:!0,autoplay:{delay:5e3,disableOnInteraction:!1},pagination:!1,navigation:!0,modules:[t,o],className:"mySwiper",children:p.map((s,i)=>e.jsx(r,{children:e.jsx("div",{className:"researchCardCont",children:e.jsxs("div",{className:"researchCardhero",children:[e.jsx("div",{className:"cardimghero"}),e.jsx("p",{className:"main",children:s.name}),e.jsx("p",{className:"desc",children:s.desc}),e.jsx("button",{className:"btn",onClick:()=>{window.open(s.link,"_blank")},children:"Learn More"})]})})},i))})]})})})]})}),u=[{title:"3D Computer Vision",desc:"Developing novel techniques to address challenging problems in 3D object detection, classification, and registration.",img:"area1.jpg"},{title:"Large-Scale Visual Computing",desc:"Innovating techniques to manage the challenges posed by the exponential growth of visual data in the era of “Big Data.”",img:"area2.jpg"},{title:"Deep Visual Computing",desc:"Creating advanced methods for deeply learning and discovering hidden visual patterns for object recognition using cutting-edge deep learning techniques.",img:"area3.jpg"},{title:"Deep Cross-Domain Models",desc:"Developing techniques to deeply mine intrinsic relationships among loosely related data across different domains, such as 2D images and 3D shapes.",img:"area4.jpg"},{title:"Deep Cross-Modality Models",desc:"Exploring novel methods to deeply understand the affinity among data from different modalities, such as 3D shapes and semantic text-based descriptions.",img:"area5.jpg"},{title:"3D Computational Structural Biology",desc:"Innovating new methods to address the significant conformational structural flexibility of biological molecules.",img:"area6.jpg"}],b=()=>{const a=Object.assign({"../assets/images/projects/area1.jpg":c,"../assets/images/projects/area2.jpg":l,"../assets/images/projects/area3.jpg":d,"../assets/images/projects/area4.jpg":g,"../assets/images/projects/area5.jpg":h,"../assets/images/projects/area6.jpg":m});return e.jsxs("div",{children:[e.jsx(j,{title:"Projects",description:"Explore the cutting edge research being done"}),e.jsx("div",{className:"sectionafterhero",children:e.jsx("div",{className:"container",children:e.jsxs("div",{className:"row",children:[e.jsx("p",{className:"headerreserach",children:" Ongoing Research"}),e.jsx("p",{className:"researchDescHro",children:"Video clips of ongoing research in lab"}),e.jsx("br",{}),"Coming soon.",e.jsx("div",{className:"fieldholders"})]})})}),e.jsx("div",{className:"resareasss",children:e.jsx("div",{className:"container",children:e.jsxs("div",{className:"row",children:[e.jsx("p",{className:"headerreserach",children:" Research Sub-Areas"}),e.jsx("p",{className:"researchDescHro",children:"With the rapid advancement in data acquisition techniques, our lab is at the forefront of addressing the exponential increase in visual data across various domains and modalities, including 2D images, 2D videos, 2D sketches, 2.5D depth images, 3D point clouds, and 3D meshed surfaces. We are dedicated to developing cutting-edge approaches for the automatic processing, understanding, and analysis of visual data. These data often exhibit high complexity, significant structural variations, intrinsic imprecision, ambiguity, and are prone to heavy noise and incompleteness. For example, cars from different manufacturers may have distinct 3D shape representations, buildings viewed from different angles may appear different in 2D views, and sketches of a horse by different individuals may vary due to experiential and cognitive differences."}),e.jsx("div",{className:"fieldholders",children:u.map((s,i)=>e.jsx("div",{className:"fieldItem",children:e.jsx("div",{className:"customCardproj",children:e.jsxs("div",{className:"cardBodyproj",children:[e.jsx("img",{className:"tokenImage",src:a[`../assets/images/projects/${s.img}`],alt:"NYU AIR LAB"}),e.jsxs("h2",{children:[s.title," "]}),e.jsx("p",{className:"description",children:s.desc})]})})},i))})]})})})]})};export{b as default};
